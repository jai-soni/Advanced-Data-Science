{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy Consumption Prediction By Appliances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Import Required Libraries\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import ExtraTreesRegressor,RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = pd.read_csv('energydata_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featureengineering(energy):\n",
    "    # Converting datatype of Date column to date time\n",
    "    energy['date'] = pd.to_datetime(energy['date'])\n",
    "\n",
    "    # Removing rv2 feature\n",
    "    del energy['rv2']\n",
    "    \n",
    "    # Removing T9 feature\n",
    "    del energy['T9']\n",
    "    \n",
    "    # Removing T6 feature\n",
    "    del energy['T6']\n",
    "    \n",
    "    # Removing rv1\n",
    "    del energy['rv1']\n",
    "    \n",
    "    # To get the month for that record\n",
    "    energy['month'] = energy['date'].dt.month\n",
    "\n",
    "    # To get the specific time for that record\n",
    "    #energy['time'] = energy['date'].dt.time\n",
    "\n",
    "    #---------------------------------------------------\n",
    "    p = []\n",
    "    q = []\n",
    "    for i in energy['date']:\n",
    "        p.append(i.strftime(\"%j\"))\n",
    "        q.append(i.hour * 60 + i.minute)\n",
    "        \n",
    "    p=list(map(int, p))\n",
    "    #---------------------------------------------------\n",
    "\n",
    "    # To get the Day of the year for that record\n",
    "    energy['DOY'] = pd.DataFrame({'DOY': p})\n",
    "\n",
    "    # To get the minutes from midnight for that record\n",
    "    energy['NSM'] = pd.DataFrame({'NSM': q})\n",
    "\n",
    "    # To get the only date \n",
    "    #energy['Only_Date'] = energy['date'].dt.date\n",
    "    #energy['Only_Date'] = pd.to_datetime(energy['Only_Date'])\n",
    "    \n",
    "    # To get the weekday for that record\n",
    "    energy['Day of Week'] = energy['date'].dt.weekday\n",
    "    \n",
    "    # Now as we have DOY (Day of year) and MNM, we can remove date variable.\n",
    "    del energy['date']\n",
    "    \n",
    "    # Generating training and testing dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    energy_train, energy_test = train_test_split(energy, test_size=0.2)\n",
    "\n",
    "    #energy.sort_index()\n",
    "    #energy_train = energy[0:int(energy.shape[0]*0.8)]\n",
    "    #energy_test = energy[int(energy.shape[0]*0.8):]\n",
    "    \n",
    "    return energy_train, energy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getXY(df):\n",
    "    \n",
    "    X = df.drop(['Appliances'],axis =1)\n",
    "    Y = df['Appliances']\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn,df_test = featureengineering(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, y_trn = getXY(df_trn)\n",
    "X_test, y_test =  getXY(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_columns = ['lights','RH_2','T3','RH_3','RH_4','RH_5','RH_7','T8','Press_mm_hg','RH_out','DOY','NSM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = X_trn[sel_columns]\n",
    "X_test = X_test[sel_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapreprocessing(df_trn,df_test):\n",
    "    \n",
    "    # Remove correlated features T6 and T9\n",
    "    #train = df_trn.drop(['date','rv1','rv2','WeekStatus', 'Day_of_week','T6', 'T9'], axis=1)\n",
    "    #test = df_test.drop(['date','rv1','rv2','WeekStatus', 'Day_of_week','T6', 'T9'], axis=1)\n",
    "    \n",
    "    # Scales the data to zero mean and unit variance\n",
    "    standard_scaler = StandardScaler()\n",
    "    \n",
    "    # Create dummy dataframes to hold the scaled train and test data\n",
    "    train_scaled = pd.DataFrame(columns=df_trn.columns, index=df_trn.index)\n",
    "    test_scaled = pd.DataFrame(columns=df_test.columns, index=df_test.index)\n",
    "\n",
    "    # Store the scaled data in new dataframes\n",
    "    train_scaled[train_scaled.columns] = standard_scaler.fit_transform(df_trn)\n",
    "    test_scaled[test_scaled.columns] = standard_scaler.fit_transform(df_test)\n",
    "    \n",
    "    # Prepare training and testing data\n",
    "    X_trn = train_scaled.drop(\"Appliances\", axis=1)\n",
    "    y_trn = train_scaled[\"Appliances\"]\n",
    "\n",
    "    X_test = test_scaled.drop(\"Appliances\", axis=1)\n",
    "    y_test = test_scaled[\"Appliances\"]\n",
    "    \n",
    "    return X_trn, y_trn, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_trn, y_scaled_trn, X_scaled_test, y_scaled_test = datapreprocessing(df_trn,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_Implementation(X_trn,y_trn,X_test,y_test):\n",
    "    \n",
    "    models = [RandomForestRegressor(random_state=42)]\n",
    "\n",
    "    TestModels = pd.DataFrame()\n",
    "    tmp = {}\n",
    "\n",
    "    for model in models:\n",
    "        # get model name\n",
    "        m = str(model)\n",
    "        tmp['Model'] = m[:m.index('(')]\n",
    "        # fit model on training dataset\n",
    "\n",
    "        start = time()\n",
    "        model.fit(X_trn, y_trn)\n",
    "        end = time()\n",
    "\n",
    "        #Predictions and Validation for Testing and Training Set\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_trn = model.predict(X_trn)\n",
    "        #R2 score\n",
    "        tmp['R2_Test'] = round(r2_score(y_test,predictions),3)\n",
    "        tmp['R2_Train'] = round(r2_score(y_trn,predictions_trn),3)\n",
    "        #Mean Absolute Error(MAE)\n",
    "        tmp['MAE_Test']= round(mean_absolute_error(y_test,predictions),3)\n",
    "        tmp['MAE_Train']= round(mean_absolute_error(y_trn,predictions_trn),3)\n",
    "        #Mean Squared Error(MSE)\n",
    "        tmp['MSE_Test']= round(mean_squared_error(y_test,predictions),3)\n",
    "        tmp['MSE_Train']= round(mean_squared_error(y_trn,predictions_trn),3)\n",
    "        #Root Mean Squared Error (RMSE)\n",
    "        tmp['RMSE_Test'] = round(np.sqrt(mean_squared_error(y_test,predictions)),3)\n",
    "        tmp['RMSE_Train'] = round(np.sqrt(mean_squared_error(y_trn,predictions_trn)),3)\n",
    "        #Mean Absolute Percentage Error\n",
    "        tmp['MAPE_Test'] =  round(np.mean(np.abs((y_test - predictions) / y_test)) * 100,3)\n",
    "        tmp['MAPE_Train'] =  round(np.mean(np.abs((y_trn - predictions_trn) / y_trn)) * 100,3)\n",
    "        #Training and Testing Scores\n",
    "        tmp['Training Score(%)'] = round(model.score(X_trn, y_trn) * 100,3)\n",
    "        tmp['Testing Score(%)'] = round(model.score(X_test, y_test) * 100,3)\n",
    "        # Training Time\n",
    "        tmp['Training Time'] = round(end-start,3)\n",
    "        # write obtained data\n",
    "        TestModels = TestModels.append([tmp])\n",
    "\n",
    "    TestModels.set_index('Model', inplace=True)\n",
    "    #print('Iteration'+str(i))\n",
    "    TestModels\n",
    "    return TestModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_Test</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>MAPE_Test</th>\n",
       "      <th>MAPE_Train</th>\n",
       "      <th>MSE_Test</th>\n",
       "      <th>MSE_Train</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>Testing Score(%)</th>\n",
       "      <th>Training Score(%)</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.336</td>\n",
       "      <td>0.129</td>\n",
       "      <td>155.464</td>\n",
       "      <td>63.284</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.296</td>\n",
       "      <td>48.662</td>\n",
       "      <td>91.212</td>\n",
       "      <td>5.721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MAE_Test  MAE_Train  MAPE_Test  MAPE_Train  MSE_Test  \\\n",
       "Model                                                                         \n",
       "RandomForestRegressor     0.336      0.129    155.464      63.284     0.513   \n",
       "\n",
       "                       MSE_Train  R2_Test  R2_Train  RMSE_Test  RMSE_Train  \\\n",
       "Model                                                                        \n",
       "RandomForestRegressor      0.088    0.487     0.912      0.717       0.296   \n",
       "\n",
       "                       Testing Score(%)  Training Score(%)  Training Time  \n",
       "Model                                                                      \n",
       "RandomForestRegressor            48.662             91.212          5.721  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_scaled = model_Implementation(X_scaled_trn, y_scaled_trn, X_scaled_test, y_scaled_test)\n",
    "results_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE_Test</th>\n",
       "      <th>MAE_Train</th>\n",
       "      <th>MAPE_Test</th>\n",
       "      <th>MAPE_Train</th>\n",
       "      <th>MSE_Test</th>\n",
       "      <th>MSE_Train</th>\n",
       "      <th>R2_Test</th>\n",
       "      <th>R2_Train</th>\n",
       "      <th>RMSE_Test</th>\n",
       "      <th>RMSE_Train</th>\n",
       "      <th>Testing Score(%)</th>\n",
       "      <th>Training Score(%)</th>\n",
       "      <th>Training Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>33.254</td>\n",
       "      <td>13.134</td>\n",
       "      <td>32.828</td>\n",
       "      <td>12.803</td>\n",
       "      <td>5057.63</td>\n",
       "      <td>916.435</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.913</td>\n",
       "      <td>71.117</td>\n",
       "      <td>30.273</td>\n",
       "      <td>52.53</td>\n",
       "      <td>91.251</td>\n",
       "      <td>2.575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       MAE_Test  MAE_Train  MAPE_Test  MAPE_Train  MSE_Test  \\\n",
       "Model                                                                         \n",
       "RandomForestRegressor    33.254     13.134     32.828      12.803   5057.63   \n",
       "\n",
       "                       MSE_Train  R2_Test  R2_Train  RMSE_Test  RMSE_Train  \\\n",
       "Model                                                                        \n",
       "RandomForestRegressor    916.435    0.525     0.913     71.117      30.273   \n",
       "\n",
       "                       Testing Score(%)  Training Score(%)  Training Time  \n",
       "Model                                                                      \n",
       "RandomForestRegressor             52.53             91.251          2.575  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model_Implementation(X_trn, y_trn, X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Hyperparameter Tuning</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Hyper Parameters selection for Extra Trees Regressor</h4>\n",
    "\n",
    "We will try adjusting the following set of hyperparameters:\n",
    "\n",
    "- n_estimators = number of trees in the foreset\n",
    "- max_features = max number of features considered for splitting a node\n",
    "- max_depth = max number of levels in each decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - Randomized Search\n",
    "\n",
    "The most important arguments in RandomizedSearchCV are n_iter, which controls the number of different combinations to try, and cv which is the number of folds to use for cross validation (we use 20 and 5 respectively). More iterations will cover a wider search space and more cv folds reduces the chances of overfitting, but raising each will increase the run time. Machine learning is a field of trade-offs, and performance vs time is one of the most fundamental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  7.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Initialize the model based on best performance from above, We got ExtraTreesRegressor \n",
    "sel_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter subset\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [10, 50, 100, 200, 250, 300, 500, 800],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"max_depth\": [None, 10, 50, 100, 200, 500]\n",
    "}\n",
    "\n",
    "# Use Randomized search to try 20 subsets from parameter space with 5-fold cross validation\n",
    "random_search = RandomizedSearchCV(sel_model, param_grid, n_iter=20, scoring=\"r2\", cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
    "random_search.fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'max_features': 'log2', 'max_depth': 100}\n"
     ]
    }
   ],
   "source": [
    "# Best Parameters for the model from Randomized Search CV\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to measure performance\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mae = mean_absolute_error(test_labels,predictions)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    rmse = np.sqrt(mean_squared_error(test_labels,predictions))\n",
    "    r2 = model.score(test_features, test_labels)\n",
    "    print('Model Performance')\n",
    "    print('R2 : {:0.3f}'.format(r2))\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('RMSE : {:0.4f}'.format(rmse)) \n",
    "    print('MAPE : {:0.4f}'.format(mae*100))\n",
    "    print('MAE: {:0.4f}'.format(mae))\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=42, verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2 : 0.525\n",
      "Average Error: 33.2536 degrees.\n",
      "RMSE : 71.1170\n",
      "MAPE : 3325.3610\n",
      "MAE: 33.2536\n"
     ]
    }
   ],
   "source": [
    "base_model = RandomForestRegressor(random_state = 42)\n",
    "base_model.fit(X_trn, y_trn)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2 : 0.913\n",
      "Average Error: 13.1340 degrees.\n",
      "RMSE : 30.2727\n",
      "MAPE : 1313.3963\n",
      "MAE: 13.1340\n"
     ]
    }
   ],
   "source": [
    "#Training Scores\n",
    "base_accuracy = evaluate(base_model, X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2 : 0.584\n",
      "Average Error: 30.7401 degrees.\n",
      "RMSE : 66.6127\n",
      "MAPE : 29.9750\n",
      "MAE: 0.2997\n",
      "Wall time: 1.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_model = random_search.best_estimator_\n",
    "best_accuracy = evaluate(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "R2 : 0.943\n",
      "Average Error: 11.2737 degrees.\n",
      "RMSE : 24.3423\n",
      "MAPE : 10.9996\n",
      "MAE: 0.1100\n"
     ]
    }
   ],
   "source": [
    "#Training scores\n",
    "best_accuracy = evaluate(best_model, X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random search allowed us to narrow down the range for each hyperparameter. Now that we know where to concentrate our search, we can explicitly specify every combination of settings to try. We do this with GridSearchCV, a method that, instead of sampling randomly from a distribution, evaluates all combinations we define. To use Grid Search, we make another grid based on the best values provided by random search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d133507ceade>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m                           cv = 3, n_jobs = 2, verbose = 2)\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Fit the grid search to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    \"n_estimators\": [300,400,500,600,800],\n",
    "    \"max_features\": [\"log2\"],\n",
    "    \"max_depth\": [50,100,150]\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "sel_model = ExtraTreesRegressor(random_state=42)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = sel_model, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 2, verbose = 2)\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_trn, y_trn)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "sel_model = LinearRegression()\n",
    "scores = cross_val_score(sel_model, X_test, y_test, cv=5)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "X, y = X_trn.values, y_trn.values\n",
    "\n",
    "\n",
    "title = \"Learning Curves (Linear Regression)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = LinearRegression()\n",
    "plot_learning_curve(estimator, title, X, y, cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves (Extra Trees Regressor)\"\n",
    "# Cross validation with 100 iterations to get smoother mean test and train\n",
    "# score curves, each time with 20% data randomly selected as a validation set.\n",
    "cv = ShuffleSplit(n_splits=100, test_size=0.2, random_state=0)\n",
    "\n",
    "estimator = ExtraTreesRegressor()\n",
    "plot_learning_curve(estimator, title, X, y, cv=cv, n_jobs=4)\n",
    "\n",
    "title = \"Learning Curves Random Forest Regressor\"\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "estimator = RandomForestRegressor()\n",
    "plot_learning_curve(estimator, title, X, y, cv=cv, n_jobs=4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(X_test,y_test,predictions):    \n",
    "    print('R2 :{:.3f}'.format(ridgeReg.score(X_test,y_test)))\n",
    "    print('MSE: {:.3f}'.format(mean_squared_error(y_test,predictions)))\n",
    "    print('RMSE: {:.3f}'.format(np.sqrt(mean_squared_error(y_test,predictions))))\n",
    "    print('MAE: {:.3f}'.format(mean_absolute_error(y_test,predictions)))\n",
    "    print('MAPE:{:.3f}'.format(np.mean(np.abs((y_test - predictions) / y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "## training the model\n",
    "\n",
    "ridgeReg = Ridge(alpha=0.05, normalize=True)\n",
    "\n",
    "ridgeReg.fit(X_trn,y_trn)\n",
    "\n",
    "predictions = ridgeReg.predict(X_test)\n",
    "getResults(X_test,y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "## training the model\n",
    "\n",
    "LassoReg = Lasso(alpha=0.005, normalize=True)\n",
    "\n",
    "LassoReg.fit(X_trn,y_trn)\n",
    "\n",
    "predictions = LassoReg.predict(X_test)\n",
    "getResults(X_test,y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "## training the model\n",
    "\n",
    "ElasticNetReg = ElasticNet(alpha=0.001, normalize=True)\n",
    "\n",
    "ElasticNetReg.fit(X_trn,y_trn)\n",
    "\n",
    "predictions = ElasticNetReg.predict(X_test)\n",
    "getResults(X_test,y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
